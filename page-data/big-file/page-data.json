{"componentChunkName":"component---src-templates-blog-post-js","path":"/big-file/","result":{"data":{"site":{"siteMetadata":{"title":"feiker的小站"}},"markdownRemark":{"id":"6e1ac9de-e67e-59bb-a4a4-51ad55c5b3ed","excerpt":"talk is cheap, show me the code! 外排序算法 将 100 亿数据拆分成 100 块，分块读取存到 100 个小文件 对 100 个小文件(1 亿数据)排序 因为内存只允许 1 亿数据操作，对 100 个文件，每次读取 100 万数据，做 100 路归并排序，将结果写入到目标文件 重复…","html":"<p>talk is cheap, show me the code!</p>\n<p>外排序算法</p>\n<ol>\n<li>将 100 亿数据拆分成 100 块，分块读取存到 100 个小文件</li>\n<li>对 100 个小文件(1 亿数据)排序</li>\n<li>因为内存只允许 1 亿数据操作，对 100 个文件，每次读取 100 万数据，做 100 路归并排序，将结果写入到目标文件</li>\n<li>重复 3 操作，依次读取剩下的数据，排序后追加到目标文件结尾</li>\n</ol>\n<h3>构造测试数据</h3>\n<p>100 亿数据，为了方便测试，用一个整数代表一条数据。\njavascript 中，Number 类型采用 IEEE754 标准中的 “双精度浮点数” 来表示一个数字，不区分整数和浮点数。IEEE754，双精度浮点数采用 64 位存储，也就是 8 个 byte。\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/7/76/General_double_precision_float.png\">\n那么 100 亿数据大概就是 <code class=\"language-text\">100 * 100000000 * 8 = 80000000000 / 1024 / 1024 / 1024 = 74.5 G</code>, OK，看了下小霸王的剩余存储空间，可以下一题了。</p>\n<p>以上纯属为了分析，因为只是为了模拟，所以数据量没必要那么大，减少数据量，改下题</p>\n<blockquote>\n<p>100 万排序问题：内存不足，一次只允许你装载和操作 1 万条数据，如何对 100 万条数据进行排序</p>\n</blockquote>\n<p>100 万大概是 <code class=\"language-text\">100 * 10000 * 8 = 8000000 / 1024 / 1024 = 7.62 M</code>, 大小上可以接受。</p>\n<h5>生成文件</h5>\n<p>生成 100w 数据的文件</p>\n<div class=\"gatsby-highlight\" data-language=\"typescript\"><pre class=\"language-typescript\"><code class=\"language-typescript\"><span class=\"token keyword\">import</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">as</span> fs <span class=\"token keyword\">from</span> <span class=\"token string\">'fs'</span>\n<span class=\"token keyword\">import</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">as</span> path <span class=\"token keyword\">from</span> <span class=\"token string\">'path'</span>\n\n<span class=\"token keyword\">const</span> <span class=\"token constant\">DATA_SIZE</span><span class=\"token punctuation\">:</span> <span class=\"token builtin\">number</span> <span class=\"token operator\">=</span> <span class=\"token number\">1000000</span>\n<span class=\"token keyword\">const</span> <span class=\"token constant\">DATA_RANGE</span><span class=\"token punctuation\">:</span> <span class=\"token builtin\">number</span> <span class=\"token operator\">=</span> <span class=\"token number\">1000000</span>\n\n<span class=\"token keyword\">const</span> data<span class=\"token punctuation\">:</span> <span class=\"token builtin\">Array</span><span class=\"token operator\">&lt;</span><span class=\"token builtin\">number</span><span class=\"token operator\">></span> <span class=\"token operator\">=</span> <span class=\"token builtin\">Array</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">from</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span> length<span class=\"token punctuation\">:</span> <span class=\"token constant\">DATA_SIZE</span> <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">map</span><span class=\"token punctuation\">(</span><span class=\"token parameter\">_</span> <span class=\"token operator\">=></span>\n  Math<span class=\"token punctuation\">.</span><span class=\"token function\">floor</span><span class=\"token punctuation\">(</span>Math<span class=\"token punctuation\">.</span><span class=\"token function\">random</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token constant\">DATA_RANGE</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">)</span>\n\nfs<span class=\"token punctuation\">.</span><span class=\"token function\">writeFile</span><span class=\"token punctuation\">(</span>path<span class=\"token punctuation\">.</span><span class=\"token function\">resolve</span><span class=\"token punctuation\">(</span>__dirname<span class=\"token punctuation\">,</span> <span class=\"token string\">'big-data'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">.</span><span class=\"token function\">join</span><span class=\"token punctuation\">(</span><span class=\"token string\">' '</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=></span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>将文件分割成 100 分，根据上述分析，每次读取的文件大小应该是 <code class=\"language-text\">8 * 10000</code></p>\n<div class=\"gatsby-highlight\" data-language=\"typescript\"><pre class=\"language-typescript\"><code class=\"language-typescript\"><span class=\"token keyword\">import</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">as</span> fs <span class=\"token keyword\">from</span> <span class=\"token string\">'fs'</span>\n<span class=\"token keyword\">import</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">as</span> path <span class=\"token keyword\">from</span> <span class=\"token string\">'path'</span>\n\n<span class=\"token keyword\">const</span> <span class=\"token function-variable function\">resolve</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token parameter\">filename<span class=\"token punctuation\">:</span> <span class=\"token builtin\">string</span></span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=></span> path<span class=\"token punctuation\">.</span><span class=\"token function\">resolve</span><span class=\"token punctuation\">(</span>__dirname<span class=\"token punctuation\">,</span> filename<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">const</span> splitedDir<span class=\"token punctuation\">:</span> <span class=\"token builtin\">string</span> <span class=\"token operator\">=</span> <span class=\"token string\">'splited'</span>\nfs<span class=\"token punctuation\">.</span><span class=\"token function\">mkdir</span><span class=\"token punctuation\">(</span><span class=\"token function\">resolve</span><span class=\"token punctuation\">(</span>splitedDir<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">{</span> recursive<span class=\"token punctuation\">:</span> <span class=\"token boolean\">true</span> <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span> <span class=\"token parameter\">err</span> <span class=\"token operator\">=></span> <span class=\"token builtin\">console</span><span class=\"token punctuation\">.</span><span class=\"token function\">error</span><span class=\"token punctuation\">(</span>err<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">const</span> readStream <span class=\"token operator\">=</span> fs<span class=\"token punctuation\">.</span><span class=\"token function\">createReadStream</span><span class=\"token punctuation\">(</span><span class=\"token function\">resolve</span><span class=\"token punctuation\">(</span><span class=\"token string\">'big-data'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">{</span>\n  highWaterMark<span class=\"token punctuation\">:</span> <span class=\"token number\">8</span> <span class=\"token operator\">*</span> <span class=\"token number\">10000</span> <span class=\"token comment\">// 以固定大小读取文件</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">let</span> count <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n\nreadStream<span class=\"token punctuation\">.</span><span class=\"token function\">on</span><span class=\"token punctuation\">(</span><span class=\"token string\">'data'</span><span class=\"token punctuation\">,</span> <span class=\"token parameter\">chuck</span> <span class=\"token operator\">=></span> <span class=\"token punctuation\">{</span>\n  fs<span class=\"token punctuation\">.</span><span class=\"token function\">writeFile</span><span class=\"token punctuation\">(</span><span class=\"token function\">resolve</span><span class=\"token punctuation\">(</span><span class=\"token template-string\"><span class=\"token template-punctuation string\">`</span><span class=\"token interpolation\"><span class=\"token interpolation-punctuation punctuation\">${</span>splitedDir<span class=\"token interpolation-punctuation punctuation\">}</span></span><span class=\"token string\">/</span><span class=\"token interpolation\"><span class=\"token interpolation-punctuation punctuation\">${</span>count<span class=\"token operator\">++</span><span class=\"token interpolation-punctuation punctuation\">}</span></span><span class=\"token template-punctuation string\">`</span></span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> chuck<span class=\"token punctuation\">,</span> <span class=\"token parameter\">err</span> <span class=\"token operator\">=></span>\n    <span class=\"token builtin\">console</span><span class=\"token punctuation\">.</span><span class=\"token function\">error</span><span class=\"token punctuation\">(</span>err<span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n\nreadStream<span class=\"token punctuation\">.</span><span class=\"token function\">on</span><span class=\"token punctuation\">(</span><span class=\"token string\">'end'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=></span> <span class=\"token punctuation\">{</span>\n  <span class=\"token builtin\">console</span><span class=\"token punctuation\">.</span><span class=\"token function\">log</span><span class=\"token punctuation\">(</span><span class=\"token string\">'write end'</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>用以上代码去分割，按照预期，应该分割成 100 个文件，每个文件 <code class=\"language-text\">8 * 10000 = 78.15k</code> 才对，当我自信满满的去看生成文件，发现只生成了 86 个文件，且每个文件的大小是 80k，86 * 80k = 6.7M 和 预期的 7.6M 也不符合，看了下生成文件的确是 6.7M</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">du</span> -h big-data\n<span class=\"token number\">6</span>.6M\tbig-data</code></pre></div>\n<p>仔细看了下生成的文件的代码，我们在存储数据的时候，是采用 <code class=\"language-text\">data.join(&#39; &#39;)</code> 转换成字符串来存储，这里的字符是用<code class=\"language-text\">utf-8</code>编码，UTF-8 编码把一个 Unicode 字符根据不同的数字大小编码成 1-6 个字节，常用的英文字母被编码成 1 个字节，汉字通常是 3 个字节，只有很生僻的字符才会被编码成 4-6 个字节，所以相比原来规规矩矩的双精度浮点数 8 个字节有压缩。</p>\n<p>不过没关系，只是为了模拟操作，86 个文件也够用</p>\n<h5>排序以及写入到目标文件</h5>\n<p>在排序之前，遇到一个新问题</p>\n<blockquote>\n<p>如何从 86 个文件中同时读取固定大小的内容，处理后可以再次读取</p>\n</blockquote>\n<p>google 了下，找到的都是如何从一个大文件分片读取，通过新建一个可读流，依靠触发’data’事件，来一点点读数据，但是我想要的是从 80 多个文件同时读取。\n流既然可以分块读取文件，那么我能不能让它停下来，开 86 个可读性流，每个流读取一块数据后停下来，待 86 个数据都被读取后并处理后，让流继续读取文件。\n问题规约为如何让可读文件流暂停，翻了下 node 文档, 可读流分为两种模式，其中一种叫<code class=\"language-text\">paused</code>, 在这种模式下，只有调用了<code class=\"language-text\">stream.read()</code>才能读取下一块内容。\n具体可以看<a href=\"https://nodejs.org/dist/latest-v13.x/docs/api/stream.html#stream_two_reading_modes\">node 的 stream 部分</a></p>\n<blockquote>\n<p>Readable streams effectively operate in one of two modes: flowing and paused. These modes are separate from object mode. A Readable stream can be in > object mode or not, regardless of whether it is in flowing mode or paused mode.\nIn flowing mode, data is read from the underlying system automatically and provided to an application as quickly as possible using events via the > > EventEmitter interface.\nIn paused mode, the stream.read() method must be called explicitly to read chunks of data from the stream.</p>\n</blockquote>\n<p>前置问题都解决了，可以开始写排序代码了</p>\n<div class=\"gatsby-highlight\" data-language=\"typescript\"><pre class=\"language-typescript\"><code class=\"language-typescript\"><span class=\"token keyword\">import</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">as</span> fs <span class=\"token keyword\">from</span> <span class=\"token string\">'fs'</span>\n<span class=\"token keyword\">import</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">as</span> path <span class=\"token keyword\">from</span> <span class=\"token string\">'path'</span>\n<span class=\"token keyword\">import</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">as</span> readline <span class=\"token keyword\">from</span> <span class=\"token string\">'readline'</span>\n\n<span class=\"token keyword\">async</span> <span class=\"token keyword\">function</span> <span class=\"token function\">createReadlines</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n  <span class=\"token keyword\">const</span> files <span class=\"token operator\">=</span> <span class=\"token keyword\">await</span> fs<span class=\"token punctuation\">.</span>promises<span class=\"token punctuation\">.</span><span class=\"token function\">readdir</span><span class=\"token punctuation\">(</span>path<span class=\"token punctuation\">.</span><span class=\"token function\">resolve</span><span class=\"token punctuation\">(</span>__dirname<span class=\"token punctuation\">,</span> <span class=\"token string\">'splited'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">const</span> channels<span class=\"token punctuation\">:</span> <span class=\"token builtin\">Array</span><span class=\"token operator\">&lt;</span>readline<span class=\"token punctuation\">.</span>Interface<span class=\"token operator\">></span> <span class=\"token operator\">=</span> files<span class=\"token punctuation\">.</span><span class=\"token function\">map</span><span class=\"token punctuation\">(</span><span class=\"token parameter\">file</span> <span class=\"token operator\">=></span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">const</span> stream <span class=\"token operator\">=</span> fs<span class=\"token punctuation\">.</span><span class=\"token function\">createReadStream</span><span class=\"token punctuation\">(</span>\n      path<span class=\"token punctuation\">.</span><span class=\"token function\">resolve</span><span class=\"token punctuation\">(</span>__dirname<span class=\"token punctuation\">,</span> <span class=\"token template-string\"><span class=\"token template-punctuation string\">`</span><span class=\"token string\">splited/</span><span class=\"token interpolation\"><span class=\"token interpolation-punctuation punctuation\">${</span>file<span class=\"token interpolation-punctuation punctuation\">}</span></span><span class=\"token template-punctuation string\">`</span></span><span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">return</span> readline<span class=\"token punctuation\">.</span><span class=\"token function\">createInterface</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span>\n      input<span class=\"token punctuation\">:</span> stream\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n\n  <span class=\"token keyword\">return</span> channels\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">async</span> <span class=\"token keyword\">function</span> <span class=\"token function\">sort</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n  <span class=\"token keyword\">const</span> distFile <span class=\"token operator\">=</span> fs<span class=\"token punctuation\">.</span><span class=\"token function\">createWriteStream</span><span class=\"token punctuation\">(</span>path<span class=\"token punctuation\">.</span><span class=\"token function\">resolve</span><span class=\"token punctuation\">(</span>__dirname<span class=\"token punctuation\">,</span> <span class=\"token string\">'out'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">const</span> channels <span class=\"token operator\">=</span> <span class=\"token keyword\">await</span> <span class=\"token function\">createReadlines</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">const</span> srcData <span class=\"token operator\">=</span> <span class=\"token builtin\">Array</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">from</span><span class=\"token punctuation\">(</span>channels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">map</span><span class=\"token punctuation\">(</span><span class=\"token parameter\">item</span> <span class=\"token operator\">=></span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n  channels<span class=\"token punctuation\">.</span><span class=\"token function\">forEach</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token parameter\">channel<span class=\"token punctuation\">,</span> index</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=></span> <span class=\"token punctuation\">{</span>\n    channel<span class=\"token punctuation\">.</span><span class=\"token function\">on</span><span class=\"token punctuation\">(</span><span class=\"token string\">'line'</span><span class=\"token punctuation\">,</span> <span class=\"token parameter\">num</span> <span class=\"token operator\">=></span> <span class=\"token punctuation\">{</span>\n      srcData<span class=\"token punctuation\">[</span>index<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token function\">push</span><span class=\"token punctuation\">(</span><span class=\"token operator\">+</span>num<span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n\n  <span class=\"token keyword\">let</span> termData <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n  <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">let</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> srcData<span class=\"token punctuation\">.</span>length<span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    termData<span class=\"token punctuation\">.</span><span class=\"token function\">push</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">,</span> srcData<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token function\">shift</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">}</span>\n\n  <span class=\"token keyword\">let</span> c <span class=\"token operator\">=</span> <span class=\"token number\">100</span>\n  <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>c<span class=\"token operator\">--</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">let</span> min <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">Infinity</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">let</span> count <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">let</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> termData<span class=\"token punctuation\">.</span>length<span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n      <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>termData<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">===</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        count <span class=\"token operator\">=</span> count <span class=\"token operator\">+</span> <span class=\"token number\">1</span>\n      <span class=\"token punctuation\">}</span> <span class=\"token keyword\">else</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>min<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">></span> termData<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n          min <span class=\"token operator\">=</span> termData\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token keyword\">const</span> <span class=\"token punctuation\">[</span>index<span class=\"token punctuation\">,</span> value<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> min\n    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>index <span class=\"token operator\">!==</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span> <span class=\"token operator\">&amp;&amp;</span> srcData<span class=\"token punctuation\">[</span>index<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>length <span class=\"token operator\">!==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n      termData<span class=\"token punctuation\">[</span>index<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>index<span class=\"token punctuation\">,</span> srcData<span class=\"token punctuation\">[</span>index<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token function\">shift</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">}</span> <span class=\"token keyword\">else</span> <span class=\"token punctuation\">{</span>\n      termData<span class=\"token punctuation\">[</span>index<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">Infinity</span><span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">}</span>\n\n    distFile<span class=\"token punctuation\">.</span><span class=\"token function\">write</span><span class=\"token punctuation\">(</span><span class=\"token template-string\"><span class=\"token template-punctuation string\">`</span><span class=\"token interpolation\"><span class=\"token interpolation-punctuation punctuation\">${</span>value<span class=\"token interpolation-punctuation punctuation\">}</span></span><span class=\"token string\"> </span><span class=\"token template-punctuation string\">`</span></span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">// 数据被处理完了</span>\n    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>count <span class=\"token operator\">===</span> termData<span class=\"token punctuation\">.</span>length<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n      <span class=\"token keyword\">break</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token function\">sort</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><a href=\"https://github.com/airuikun/Weekly-FE-Interview/issues/18\">原题地址</a></p>","frontmatter":{"title":"大文件数据排序","date":"December 14, 2019","description":"100亿排序问题：内存不足，一次只允许你装载和操作1亿条数据，如何对100亿条数据进行排序"}}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/big-file/","previous":{"fields":{"slug":"/git-in-deepth/"},"frontmatter":{"title":"深度理解git"}},"next":null}}}